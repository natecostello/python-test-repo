{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import shock synthesis function from utilities\n",
    "from mdof_utilities import synthesize_shock_pulse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the example and create plots\n",
    "# Spec like the example on p.7: (10 Hz, 9.4 g) → (80 Hz, 75 g) → (2000 Hz, 75 g)\n",
    "srs_spec = np.array([[10.0, 9.4],\n",
    "                     [80.0, 75.0],\n",
    "                     [2000.0, 75.0]])\n",
    "\n",
    "print(\"Synthesizing shock signal to match SRS specification...\")\n",
    "t, acc_g, info = synthesize_shock_pulse(\n",
    "    srs_spec, fs=20480, duration=0.25, q=10, freqs_per_octave=12,\n",
    "    n_trials=60, inner_iters=16, rng_seed=3, basis=\"damped_sine\"\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Time history of synthesized acceleration\n",
    "ax1.plot(t * 1000, acc_g, 'b-', linewidth=1)\n",
    "ax1.set_xlabel('Time (ms)')\n",
    "ax1.set_ylabel('Acceleration (G)')\n",
    "ax1.set_title(f'Synthesized Shock Acceleration Signal\\n'\n",
    "              f'Peak: {info[\"peak_accel_g\"]:.1f} G, Duration: {0.25*1000:.0f} ms')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: SRS comparison (target vs achieved)\n",
    "ax2.loglog(srs_spec[:, 0], srs_spec[:, 1], 'ro-', linewidth=2, markersize=8, \n",
    "           label='Target SRS Spec', markerfacecolor='white', markeredgewidth=2)\n",
    "ax2.loglog(info[\"freqs_hz\"], info[\"target_srs_g\"], 'r--', alpha=0.7, \n",
    "           label='Target SRS (interpolated)')\n",
    "ax2.loglog(info[\"freqs_hz\"], info[\"achieved_srs_g\"], 'b-', linewidth=2, \n",
    "           label='Achieved SRS')\n",
    "\n",
    "ax2.set_xlabel('Frequency (Hz)')\n",
    "ax2.set_ylabel('SRS Acceleration (G)')\n",
    "ax2.set_title(f'Shock Response Spectrum Comparison\\n'\n",
    "              f'Q = {info[\"q\"]:.0f}, Max Error: {info[\"max_abs_error_db\"]:.2f} dB, '\n",
    "              f'Winner Trial: {info[\"winner_trial\"]}')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim([srs_spec[0, 0] * 0.8, srs_spec[-1, 0] * 1.2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary information\n",
    "print(f\"\\nSynthesis Summary:\")\n",
    "print(f\"- Duration: {0.25*1000:.0f} ms\")\n",
    "print(f\"- Sample rate: {info['fs']:.0f} Hz\")\n",
    "print(f\"- Q factor: {info['q']:.0f}\")\n",
    "print(f\"- Peak acceleration: {info['peak_accel_g']:.1f} G\")\n",
    "print(f\"- Max SRS error: {info['max_abs_error_db']:.2f} dB\")\n",
    "print(f\"- Winning trial: {info['winner_trial']} (out of 60)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate a half-sine pulse for SRS analysis and synthesis comparison\n",
    "print(\"Complete Half-Sine Pulse to SRS Synthesis Workflow\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Import required functions\n",
    "import time\n",
    "from mdof_utilities import generate_half_sine_pulse, shock_response_spectrum\n",
    "\n",
    "print(\"\\n1. Generating original half-sine pulse...\")\n",
    "\n",
    "# Define half-sine pulse parameters\n",
    "pulse_amplitude = 50    # 50g peak acceleration\n",
    "pulse_duration = 0.02  # 2 ms duration\n",
    "total_time = 0.1       # 100 ms total signal length\n",
    "sample_rate = 20480    # High sample rate for accuracy\n",
    "\n",
    "# Generate the half-sine pulse using the utility function\n",
    "t_original, a_original = generate_half_sine_pulse(\n",
    "    amplitude=pulse_amplitude,\n",
    "    duration=pulse_duration, \n",
    "    total_time=total_time,\n",
    "    sample_rate=sample_rate\n",
    ")\n",
    "\n",
    "print(f\"   - Pulse amplitude: {pulse_amplitude} g\")\n",
    "print(f\"   - Pulse duration: {pulse_duration*1000:.1f} ms\") \n",
    "print(f\"   - Total signal length: {total_time*1000:.0f} ms\")\n",
    "print(f\"   - Sample rate: {sample_rate} Hz\")\n",
    "print(f\"   - Number of samples: {len(t_original)}\")\n",
    "\n",
    "# Plot the generated pulse\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t_original * 1000, a_original, 'b-', linewidth=2)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Acceleration (g)')\n",
    "plt.title(f'Generated Half-Sine Pulse\\n{pulse_amplitude}g peak, {pulse_duration*1000:.1f}ms duration')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom view of just the pulse\n",
    "pulse_end_time = pulse_duration * 2  # Show twice the pulse duration\n",
    "pulse_mask = t_original <= pulse_end_time\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(t_original[pulse_mask] * 1000, a_original[pulse_mask], 'r-', linewidth=2)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Acceleration (g)')\n",
    "plt.title(f'Pulse Detail (First {pulse_end_time*1000:.1f}ms)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute SRS of the half-sine pulse\n",
    "print(\"\\n2. Computing SRS of the original pulse...\")\n",
    "\n",
    "# Define frequency range for SRS calculation\n",
    "freq_min = 10.0     # 10 Hz minimum\n",
    "freq_max = 1000.0   # 1000 Hz maximum\n",
    "n_freq = 25         # 25 frequency points (optimized for speed)\n",
    "\n",
    "freq_range = np.logspace(np.log10(freq_min), np.log10(freq_max), n_freq)\n",
    "\n",
    "# Calculate SRS with optimized settings\n",
    "start_time = time.time()\n",
    "srs_original = shock_response_spectrum(\n",
    "    t_original, a_original, \n",
    "    freq_range=freq_range,\n",
    "    damping_ratio=0.05,  # Q = 10 (5% damping)\n",
    "    speed_level=\"optimal\"\n",
    ")\n",
    "srs_time = time.time() - start_time\n",
    "\n",
    "print(f\"   - Frequency range: {freq_min:.0f} to {freq_max:.0f} Hz\")\n",
    "print(f\"   - Number of frequencies: {n_freq}\")\n",
    "print(f\"   - SRS calculation time: {srs_time:.2f} seconds\")\n",
    "print(f\"   - Peak SRS: {np.max(srs_original):.1f} g at {freq_range[np.argmax(srs_original)]:.1f} Hz\")\n",
    "\n",
    "# Plot the SRS\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.loglog(freq_range, srs_original, 'ro-', linewidth=2, markersize=6, \n",
    "           markerfacecolor='white', markeredgewidth=2)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('SRS Acceleration (g)')\n",
    "plt.title(f'SRS of Original Half-Sine Pulse (Q=10)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use the SRS as a target specification for synthesis\n",
    "print(\"\\n3. Creating target SRS specification...\")\n",
    "\n",
    "# Convert the computed SRS into the format expected by synthesize_shock_srs\n",
    "# Format: [[freq1, srs1], [freq2, srs2], ...]\n",
    "srs_target_spec = np.column_stack([freq_range, srs_original])\n",
    "\n",
    "print(f\"   - Target specification created with {len(srs_target_spec)} points\")\n",
    "print(f\"   - Frequency range: {srs_target_spec[0,0]:.1f} to {srs_target_spec[-1,0]:.1f} Hz\")\n",
    "print(f\"   - SRS range: {srs_target_spec[:,1].min():.1f} to {srs_target_spec[:,1].max():.1f} g\")\n",
    "\n",
    "# Step 4: Synthesize a signal that matches this SRS\n",
    "print(\"\\n4. Synthesizing signal to match the target SRS...\")\n",
    "\n",
    "synthesis_params = {\n",
    "    'fs': 20480,           # Higher sample rate for better accuracy\n",
    "    'duration': 0.25,      # 250 ms duration\n",
    "    'q': 10,              # Q = 10 (same as SRS calculation)\n",
    "    'freqs_per_octave': 12, # Reduced for speed\n",
    "    'n_trials': 300,        # Moderate number of trials\n",
    "    'inner_iters': 10,     # Moderate iterations\n",
    "    'rng_seed': 41         # For reproducibility\n",
    "}\n",
    "\n",
    "print(f\"   - Sample rate: {synthesis_params['fs']} Hz\")\n",
    "print(f\"   - Duration: {synthesis_params['duration']*1000:.0f} ms\")\n",
    "print(f\"   - Trials: {synthesis_params['n_trials']}\")\n",
    "\n",
    "start_time = time.time()\n",
    "t_synth, acc_synth, info_synth = synthesize_shock_pulse(\n",
    "    srs_target_spec, **synthesis_params\n",
    ")\n",
    "synth_time = time.time() - start_time\n",
    "\n",
    "print(f\"   - Synthesis completed in {synth_time:.1f} seconds\")\n",
    "print(f\"   - Peak synthesized acceleration: {info_synth['peak_accel_g']:.1f} g\")\n",
    "print(f\"   - SRS matching error: {info_synth['max_abs_error_db']:.2f} dB\")\n",
    "print(f\"   - Winner trial: {info_synth['winner_trial']}/{synthesis_params['n_trials']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compare original pulse with synthesized signal\n",
    "print(\"\\n5. Comparing results...\")\n",
    "\n",
    "# Create comprehensive comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Time domain comparison (first 50 ms)\n",
    "time_limit = 0.05  # 50 ms\n",
    "mask_orig = t_original <= time_limit\n",
    "mask_synth = t_synth <= time_limit\n",
    "\n",
    "axes[0,0].plot(t_original[mask_orig] * 1000, a_original[mask_orig], \n",
    "               'b-', linewidth=2, label=f'Original Half-Sine ({pulse_amplitude}g peak)')\n",
    "axes[0,0].plot(t_synth[mask_synth] * 1000, acc_synth[mask_synth], \n",
    "               'r-', linewidth=1, alpha=0.8, \n",
    "               label=f'Synthesized ({info_synth[\"peak_accel_g\"]:.0f}g peak)')\n",
    "axes[0,0].set_xlabel('Time (ms)')\n",
    "axes[0,0].set_ylabel('Acceleration (g)')\n",
    "axes[0,0].set_title('Time Domain Comparison (First 50ms)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: SRS comparison\n",
    "axes[0,1].loglog(freq_range, srs_original, 'bo-', linewidth=2, markersize=6,\n",
    "                 markerfacecolor='white', markeredgewidth=2, label='Target SRS (Original)')\n",
    "axes[0,1].loglog(info_synth[\"freqs_hz\"], info_synth[\"target_srs_g\"], 'b--', \n",
    "                 alpha=0.7, label='Target SRS (Interpolated)')\n",
    "axes[0,1].loglog(info_synth[\"freqs_hz\"], info_synth[\"achieved_srs_g\"], 'r-', \n",
    "                 linewidth=2, label='Achieved SRS (Synthesized)')\n",
    "axes[0,1].set_xlabel('Frequency (Hz)')\n",
    "axes[0,1].set_ylabel('SRS Acceleration (g)')\n",
    "axes[0,1].set_title(f'SRS Comparison (Max Error: {info_synth[\"max_abs_error_db\"]:.2f} dB)')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: SRS Error\n",
    "srs_error_db = 20 * np.log10(info_synth[\"achieved_srs_g\"] / info_synth[\"target_srs_g\"])\n",
    "axes[1,0].semilogx(info_synth[\"freqs_hz\"], srs_error_db, 'g-', linewidth=2)\n",
    "axes[1,0].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1,0].axhline(y=1, color='r', linestyle=':', alpha=0.5, label='±1 dB')\n",
    "axes[1,0].axhline(y=-1, color='r', linestyle=':', alpha=0.5)\n",
    "axes[1,0].set_xlabel('Frequency (Hz)')\n",
    "axes[1,0].set_ylabel('SRS Error (dB)')\n",
    "axes[1,0].set_title('SRS Matching Error vs Frequency')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Full time domain signals\n",
    "axes[1,1].plot(t_original * 1000, a_original, 'b-', linewidth=1.5, \n",
    "               label=f'Original Half-Sine ({pulse_duration*1000:.1f}ms)')\n",
    "axes[1,1].plot(t_synth * 1000, acc_synth, 'r-', linewidth=1, alpha=0.8,\n",
    "               label=f'Synthesized ({synthesis_params[\"duration\"]*1000:.0f}ms)')\n",
    "axes[1,1].set_xlabel('Time (ms)')\n",
    "axes[1,1].set_ylabel('Acceleration (g)')\n",
    "axes[1,1].set_title('Complete Time History Comparison')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SYNTHESIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original pulse:\")\n",
    "print(f\"  - Type: Half-sine\")\n",
    "print(f\"  - Peak: {pulse_amplitude} g\")\n",
    "print(f\"  - Duration: {pulse_duration*1000:.1f} ms\")\n",
    "print(f\"  - Peak SRS: {np.max(srs_original):.1f} g\")\n",
    "\n",
    "print(f\"\\nSynthesized signal:\")\n",
    "print(f\"  - Peak: {info_synth['peak_accel_g']:.1f} g\")\n",
    "print(f\"  - Duration: {synthesis_params['duration']*1000:.0f} ms\")  \n",
    "print(f\"  - Peak SRS: {np.max(info_synth['achieved_srs_g']):.1f} g\")\n",
    "print(f\"  - SRS matching error: {info_synth['max_abs_error_db']:.2f} dB\")\n",
    "print(f\"  - Synthesis time: {synth_time:.1f} seconds\")\n",
    "\n",
    "print(f\"\\nConclusion:\")\n",
    "peak_ratio = info_synth['peak_accel_g'] / pulse_amplitude\n",
    "print(f\"  - Peak amplitude ratio: {peak_ratio:.2f}x\")\n",
    "if info_synth['max_abs_error_db'] < 1.0:\n",
    "    print(f\"  - ✅ Excellent SRS match (< 1 dB error)\")\n",
    "elif info_synth['max_abs_error_db'] < 3.0:\n",
    "    print(f\"  - ✅ Good SRS match (< 3 dB error)\")\n",
    "else:\n",
    "    print(f\"  - ⚠️ Moderate SRS match ({info_synth['max_abs_error_db']:.1f} dB error)\")\n",
    "\n",
    "print(f\"  - The synthesized signal successfully reproduces the SRS characteristics\")\n",
    "print(f\"    of the original half-sine pulse using a complex wavelet series.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance and Method Comparison: Wavelet vs Damped Sine Basis\n",
    "print(\"SYNTHESIS BASIS COMPARISON: WAVELET vs DAMPED SINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Common parameters for fair comparison\n",
    "common_params = {\n",
    "    'fs': 20480,\n",
    "    'duration': 0.25,\n",
    "    'q': 10,\n",
    "    'freqs_per_octave': 18,\n",
    "    'n_trials': 200,\n",
    "    'inner_iters': 12,\n",
    "    'rng_seed': 42,\n",
    "    # Shock-shaping parameters\n",
    "    't0': 0.010,\n",
    "    'tail_span': 0.060,\n",
    "    'focus': 0.85,\n",
    "    'late_energy_tau': 0.050,\n",
    "    'w_time': 0.6,\n",
    "    'w_simplicity': 0.08\n",
    "}\n",
    "\n",
    "print(\"\\n1. Testing Wavelet basis (NESC wavelets)...\")\n",
    "start_time = time.time()\n",
    "t_wavelet, acc_wavelet, info_wavelet = synthesize_shock_pulse(\n",
    "    srs_target_spec,\n",
    "    basis=\"wavelet\",\n",
    "    **common_params\n",
    ")\n",
    "time_wavelet = time.time() - start_time\n",
    "\n",
    "print(f\"   - Computation time: {time_wavelet:.2f} seconds\")\n",
    "print(f\"   - Peak acceleration: {info_wavelet['peak_accel_g']:.1f} g\")\n",
    "print(f\"   - SRS matching error: {info_wavelet['max_abs_error_db']:.2f} dB\")\n",
    "print(f\"   - Time concentration score: {info_wavelet.get('time_concentration_score', 'N/A')}\")\n",
    "print(f\"   - Simplicity score: {info_wavelet.get('simplicity_score', 'N/A')}\")\n",
    "\n",
    "print(\"\\n2. Testing Damped sine basis...\")\n",
    "start_time = time.time()\n",
    "t_damped, acc_damped, info_damped = synthesize_shock_pulse(\n",
    "    srs_target_spec,\n",
    "    basis=\"damped_sine\",\n",
    "    ds_zeta=0.06,  # Damping ratio for damped sines (≈ 1/(2*Q))\n",
    "    zero_drift_fix=\"poly\",  # Optional drift cleanup\n",
    "    **common_params\n",
    ")\n",
    "time_damped = time.time() - start_time\n",
    "\n",
    "print(f\"   - Computation time: {time_damped:.2f} seconds\")\n",
    "print(f\"   - Peak acceleration: {info_damped['peak_accel_g']:.1f} g\")\n",
    "print(f\"   - SRS matching error: {info_damped['max_abs_error_db']:.2f} dB\")\n",
    "print(f\"   - Time concentration score: {info_damped.get('time_concentration_score', 'N/A')}\")\n",
    "print(f\"   - Simplicity score: {info_damped.get('simplicity_score', 'N/A')}\")\n",
    "print(f\"   - Damped sine damping ratio: 0.06 (Q ≈ 8.3)\")\n",
    "\n",
    "# Quick comparison summary\n",
    "print(f\"\\n3. Quick Comparison:\")\n",
    "speed_improvement = ((time_wavelet - time_damped) / time_wavelet) * 100\n",
    "accuracy_diff = info_wavelet['max_abs_error_db'] - info_damped['max_abs_error_db']\n",
    "peak_ratio_w = info_wavelet['peak_accel_g'] / pulse_amplitude\n",
    "peak_ratio_d = info_damped['peak_accel_g'] / pulse_amplitude\n",
    "\n",
    "print(f\"   - Speed difference: {speed_improvement:+.1f}% (+ means damped sine faster)\")\n",
    "print(f\"   - Accuracy difference: {accuracy_diff:+.2f} dB (+ means wavelet more accurate)\")\n",
    "print(f\"   - Peak ratios: Wavelet {peak_ratio_w:.2f}x, Damped Sine {peak_ratio_d:.2f}x original\")\n",
    "\n",
    "if abs(accuracy_diff) < 0.5:\n",
    "    print(f\"   - Both methods achieve similar SRS accuracy\")\n",
    "elif accuracy_diff > 0:\n",
    "    print(f\"   - Wavelet method is more accurate by {accuracy_diff:.1f} dB\")\n",
    "else:\n",
    "    print(f\"   - Damped sine method is more accurate by {abs(accuracy_diff):.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Comparison Plots and Analysis\n",
    "print(\"\\n4. Detailed Performance Analysis...\")\n",
    "\n",
    "# Create comprehensive comparison figure\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "\n",
    "# Plot 1: Time domain comparison (focus on shock region)\n",
    "shock_time = 0.08  # Focus on first 80ms where main shock occurs\n",
    "mask_w = t_wavelet <= shock_time\n",
    "mask_d = t_damped <= shock_time\n",
    "mask_o = t_original <= shock_time\n",
    "\n",
    "axes[0,0].plot(t_original[mask_o] * 1000, a_original[mask_o], 'k-', linewidth=2, \n",
    "               label='Original Half-Sine', alpha=0.8)\n",
    "axes[0,0].plot(t_wavelet[mask_w] * 1000, acc_wavelet[mask_w], 'b-', linewidth=1.5, \n",
    "               label=f'Wavelet Basis (Peak: {info_wavelet[\"peak_accel_g\"]:.0f}g)', alpha=0.8)\n",
    "axes[0,0].plot(t_damped[mask_d] * 1000, acc_damped[mask_d], 'r-', linewidth=1.5,\n",
    "               label=f'Damped Sine Basis (Peak: {info_damped[\"peak_accel_g\"]:.0f}g)', alpha=0.8)\n",
    "axes[0,0].set_xlabel('Time (ms)')\n",
    "axes[0,0].set_ylabel('Acceleration (g)')\n",
    "axes[0,0].set_title('Time Domain Comparison (Main Shock Region)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: SRS comparison\n",
    "axes[0,1].loglog(freq_range, srs_original, 'ko-', linewidth=2, markersize=6,\n",
    "                 markerfacecolor='white', markeredgewidth=2, label='Target SRS (Original)')\n",
    "axes[0,1].loglog(info_wavelet[\"freqs_hz\"], info_wavelet[\"achieved_srs_g\"], 'b-', \n",
    "                 linewidth=2, label=f'Wavelet (±{info_wavelet[\"max_abs_error_db\"]:.2f} dB)')\n",
    "axes[0,1].loglog(info_damped[\"freqs_hz\"], info_damped[\"achieved_srs_g\"], 'r-', \n",
    "                 linewidth=2, label=f'Damped Sine (±{info_damped[\"max_abs_error_db\"]:.2f} dB)')\n",
    "axes[0,1].set_xlabel('Frequency (Hz)')\n",
    "axes[0,1].set_ylabel('SRS Acceleration (g)')\n",
    "axes[0,1].set_title('SRS Matching Comparison')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: SRS Error comparison\n",
    "srs_err_wavelet = 20 * np.log10(info_wavelet[\"achieved_srs_g\"] / info_wavelet[\"target_srs_g\"])\n",
    "srs_err_damped = 20 * np.log10(info_damped[\"achieved_srs_g\"] / info_damped[\"target_srs_g\"])\n",
    "\n",
    "axes[1,0].semilogx(info_wavelet[\"freqs_hz\"], srs_err_wavelet, 'b-', linewidth=2, \n",
    "                   label='Wavelet Basis')\n",
    "axes[1,0].semilogx(info_damped[\"freqs_hz\"], srs_err_damped, 'r-', linewidth=2, \n",
    "                   label='Damped Sine Basis')\n",
    "axes[1,0].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1,0].axhline(y=1, color='gray', linestyle=':', alpha=0.5, label='±1 dB')\n",
    "axes[1,0].axhline(y=-1, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1,0].set_xlabel('Frequency (Hz)')\n",
    "axes[1,0].set_ylabel('SRS Error (dB)')\n",
    "axes[1,0].set_title('SRS Matching Error vs Frequency')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].set_ylim([-8, 8])\n",
    "\n",
    "# Plot 4: Frequency content comparison (FFT)\n",
    "from scipy.fft import fft, fftfreq\n",
    "n_fft = len(t_wavelet)\n",
    "freqs_fft = fftfreq(n_fft, 1/20480)[:n_fft//2]\n",
    "\n",
    "fft_wavelet = np.abs(fft(acc_wavelet)[:n_fft//2])\n",
    "fft_damped = np.abs(fft(acc_damped)[:n_fft//2]) \n",
    "fft_original = np.abs(fft(a_original)[:len(a_original)//2])\n",
    "freqs_orig = fftfreq(len(a_original), 1/sample_rate)[:len(a_original)//2]\n",
    "\n",
    "axes[1,1].loglog(freqs_orig, fft_original, 'k-', linewidth=2, alpha=0.7, label='Original')\n",
    "axes[1,1].loglog(freqs_fft, fft_wavelet, 'b-', linewidth=1.5, alpha=0.8, label='Wavelet')\n",
    "axes[1,1].loglog(freqs_fft, fft_damped, 'r-', linewidth=1.5, alpha=0.8, label='Damped Sine')\n",
    "axes[1,1].set_xlabel('Frequency (Hz)')\n",
    "axes[1,1].set_ylabel('FFT Magnitude')\n",
    "axes[1,1].set_title('Frequency Content Comparison')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].set_xlim([1, 2000])\n",
    "\n",
    "# Plot 5: Signal energy concentration (cumulative energy)\n",
    "def cumulative_energy(signal, dt):\n",
    "    \"\"\"Calculate cumulative energy over time\"\"\"\n",
    "    energy = np.cumsum(signal**2) * dt\n",
    "    return energy / energy[-1]  # Normalize to 1\n",
    "\n",
    "dt_w = t_wavelet[1] - t_wavelet[0]\n",
    "dt_d = t_damped[1] - t_damped[0]\n",
    "dt_o = t_original[1] - t_original[0]\n",
    "\n",
    "cum_energy_w = cumulative_energy(acc_wavelet, dt_w)\n",
    "cum_energy_d = cumulative_energy(acc_damped, dt_d)\n",
    "cum_energy_o = cumulative_energy(a_original, dt_o)\n",
    "\n",
    "axes[2,0].plot(t_original * 1000, cum_energy_o, 'k-', linewidth=2, label='Original')\n",
    "axes[2,0].plot(t_wavelet * 1000, cum_energy_w, 'b-', linewidth=2, label='Wavelet')\n",
    "axes[2,0].plot(t_damped * 1000, cum_energy_d, 'r-', linewidth=2, label='Damped Sine')\n",
    "axes[2,0].axhline(y=0.9, color='gray', linestyle='--', alpha=0.5, label='90% Energy')\n",
    "axes[2,0].set_xlabel('Time (ms)')\n",
    "axes[2,0].set_ylabel('Cumulative Energy Fraction')\n",
    "axes[2,0].set_title('Energy Concentration Over Time')\n",
    "axes[2,0].legend()\n",
    "axes[2,0].grid(True, alpha=0.3)\n",
    "axes[2,0].set_xlim([0, 100])\n",
    "\n",
    "# Plot 6: Performance metrics comparison\n",
    "metrics_names = ['Time (s)', 'Peak (g)', 'SRS Error (dB)']\n",
    "wavelet_vals = [time_wavelet, info_wavelet['peak_accel_g'], info_wavelet['max_abs_error_db']]\n",
    "damped_vals = [time_damped, info_damped['peak_accel_g'], info_damped['max_abs_error_db']]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[2,1].bar(x - width/2, wavelet_vals, width, label='Wavelet', color='blue', alpha=0.7)\n",
    "bars2 = axes[2,1].bar(x + width/2, damped_vals, width, label='Damped Sine', color='red', alpha=0.7)\n",
    "\n",
    "axes[2,1].set_xlabel('Performance Metrics')\n",
    "axes[2,1].set_ylabel('Values')\n",
    "axes[2,1].set_title('Performance Metrics Comparison')\n",
    "axes[2,1].set_xticks(x)\n",
    "axes[2,1].set_xticklabels(metrics_names)\n",
    "axes[2,1].legend()\n",
    "axes[2,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar1, bar2, val1, val2) in enumerate(zip(bars1, bars2, wavelet_vals, damped_vals)):\n",
    "    if i == 0:  # Time\n",
    "        axes[2,1].text(bar1.get_x() + bar1.get_width()/2., bar1.get_height() + 0.02, \n",
    "                       f'{val1:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        axes[2,1].text(bar2.get_x() + bar2.get_width()/2., bar2.get_height() + 0.02, \n",
    "                       f'{val2:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    elif i == 1:  # Peak\n",
    "        axes[2,1].text(bar1.get_x() + bar1.get_width()/2., bar1.get_height() + 1, \n",
    "                       f'{val1:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "        axes[2,1].text(bar2.get_x() + bar2.get_width()/2., bar2.get_height() + 1, \n",
    "                       f'{val2:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "    else:  # Error\n",
    "        axes[2,1].text(bar1.get_x() + bar1.get_width()/2., bar1.get_height() + 0.05, \n",
    "                       f'{val1:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        axes[2,1].text(bar2.get_x() + bar2.get_width()/2., bar2.get_height() + 0.05, \n",
    "                       f'{val2:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary analysis\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"BASIS COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} {'Wavelet Basis':<20} {'Damped Sine Basis':<20} {'Winner':<15}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Performance comparison\n",
    "speed_winner = \"Damped Sine\" if time_damped < time_wavelet else \"Wavelet\"\n",
    "accuracy_winner = \"Wavelet\" if info_wavelet['max_abs_error_db'] < info_damped['max_abs_error_db'] else \"Damped Sine\"\n",
    "peak_ratio_w = info_wavelet['peak_accel_g'] / pulse_amplitude\n",
    "peak_ratio_d = info_damped['peak_accel_g'] / pulse_amplitude\n",
    "peak_winner = \"Damped Sine\" if abs(peak_ratio_d - 1.0) < abs(peak_ratio_w - 1.0) else \"Wavelet\"\n",
    "\n",
    "print(f\"{'Computation Time (s)':<25} {time_wavelet:<20.2f} {time_damped:<20.2f} {speed_winner:<15}\")\n",
    "print(f\"{'SRS Error (dB)':<25} {info_wavelet['max_abs_error_db']:<20.2f} {info_damped['max_abs_error_db']:<20.2f} {accuracy_winner:<15}\")\n",
    "print(f\"{'Peak Acceleration (g)':<25} {info_wavelet['peak_accel_g']:<20.0f} {info_damped['peak_accel_g']:<20.0f} {peak_winner:<15}\")\n",
    "print(f\"{'Peak Ratio to Original':<25} {peak_ratio_w:<20.2f} {peak_ratio_d:<20.2f} {peak_winner:<15}\")\n",
    "\n",
    "print(f\"\\nBASIS CHARACTERISTICS:\")\n",
    "print(f\"• Wavelet Basis: Compact NESC wavelets with zero net impulse\")\n",
    "print(f\"• Damped Sine Basis: A*exp(-ζ*2πf*t)*sin(2πf*t) with ζ=0.06\")\n",
    "print(f\"• Both use iterative SRS-based amplitude scaling\")\n",
    "\n",
    "print(f\"\\nCONCLUSIONS:\")\n",
    "print(f\"• SRS Accuracy: {accuracy_winner} basis achieves better SRS matching\")\n",
    "print(f\"• Computational Speed: {speed_winner} basis is faster\") \n",
    "print(f\"• Peak Amplitude Control: {peak_winner} basis better preserves amplitude relationships\")\n",
    "\n",
    "print(f\"\\nRECOMMENDATIONS:\")\n",
    "if accuracy_winner == \"Wavelet\":\n",
    "    print(f\"• For precision applications: Use wavelet basis\")\n",
    "    print(f\"• For rapid analysis: Use damped sine basis\")\n",
    "else:\n",
    "    print(f\"• For precision applications: Use damped sine basis\")  \n",
    "    print(f\"• For rapid analysis: Use wavelet basis\")\n",
    "    \n",
    "print(f\"• Wavelet basis: More mathematically sophisticated, typically more accurate\")\n",
    "print(f\"• Damped sine basis: More physically intuitive, potentially faster convergence\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETER SENSITIVITY ANALYSIS: Runtime and Accuracy Scaling\n",
    "print(\"SYNTHESIS PARAMETER SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Examining individual effects of freqs_per_octave, n_trials, and inner_iters\")\n",
    "print(\"on both Wavelet and Damped Sine synthesis methods\")\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Base parameters for sensitivity analysis\n",
    "base_params = {\n",
    "    'fs': 20480,\n",
    "    'duration': 0.25,\n",
    "    'q': 10,\n",
    "    'rng_seed': 123,  # Fixed seed for reproducible comparison\n",
    "    't0': 0.010,\n",
    "    'tail_span': 0.060,\n",
    "    'focus': 0.85,\n",
    "    'late_energy_tau': 0.050,\n",
    "    'w_time': 0.6,\n",
    "    'w_simplicity': 0.08\n",
    "}\n",
    "\n",
    "# Parameter ranges to test (carefully chosen for reasonable runtime)\n",
    "test_ranges = {\n",
    "    'freqs_per_octave': [6, 12, 18, 24],           # Frequency resolution\n",
    "    'n_trials': [25, 50, 100, 200],               # Search breadth\n",
    "    'inner_iters': [5, 10, 15, 20]                # Convergence iterations\n",
    "}\n",
    "\n",
    "# Initialize results storage\n",
    "results = []\n",
    "\n",
    "print(f\"\\nTesting parameter ranges:\")\n",
    "for param, values in test_ranges.items():\n",
    "    print(f\"  - {param}: {values}\")\n",
    "\n",
    "print(f\"\\nStarting sensitivity analysis...\")\n",
    "print(f\"Total tests per method: {len(test_ranges['freqs_per_octave']) + len(test_ranges['n_trials']) + len(test_ranges['inner_iters'])} = {sum(len(v) for v in test_ranges.values())}\")\n",
    "print(f\"Estimated runtime: ~2-3 minutes per method\\n\")\n",
    "\n",
    "# Function to run a single test\n",
    "def run_sensitivity_test(basis_name, param_name, param_value, srs_spec):\n",
    "    \"\"\"Run synthesis with one parameter varied, others at baseline\"\"\"\n",
    "    # Baseline parameter values\n",
    "    test_params = base_params.copy()\n",
    "    test_params.update({\n",
    "        'freqs_per_octave': 12,\n",
    "        'n_trials': 50,\n",
    "        'inner_iters': 10\n",
    "    })\n",
    "    \n",
    "    # Override the parameter being tested\n",
    "    test_params[param_name] = param_value\n",
    "    \n",
    "    # Add basis-specific parameters\n",
    "    if basis_name == 'wavelet':\n",
    "        test_params['basis'] = 'wavelet'\n",
    "    else:\n",
    "        test_params.update({\n",
    "            'basis': 'damped_sine',\n",
    "            'ds_zeta': 0.06,\n",
    "            'zero_drift_fix': 'poly'\n",
    "        })\n",
    "    \n",
    "    # Run synthesis with timing\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        t_result, acc_result, info_result = synthesize_shock_pulse(srs_spec, **test_params)\n",
    "        runtime = time.time() - start_time\n",
    "        success = True\n",
    "        error_msg = None\n",
    "    except Exception as e:\n",
    "        runtime = time.time() - start_time\n",
    "        success = False\n",
    "        error_msg = str(e)\n",
    "        info_result = {'max_abs_error_db': np.inf, 'peak_accel_g': 0}\n",
    "    \n",
    "    return {\n",
    "        'basis': basis_name,\n",
    "        'parameter': param_name,\n",
    "        'param_value': param_value,\n",
    "        'runtime_s': runtime,\n",
    "        'srs_error_db': info_result['max_abs_error_db'] if success else np.inf,\n",
    "        'peak_accel_g': info_result['peak_accel_g'] if success else 0,\n",
    "        'success': success,\n",
    "        'error_msg': error_msg,\n",
    "        'winner_trial': info_result.get('winner_trial', -1) if success else -1\n",
    "    }\n",
    "\n",
    "# Run all sensitivity tests\n",
    "test_count = 0\n",
    "total_tests = 2 * sum(len(values) for values in test_ranges.values())\n",
    "\n",
    "for basis_idx, basis in enumerate(['wavelet', 'damped_sine']):\n",
    "    print(f\"\\nTesting {basis.upper()} BASIS ({basis_idx+1}/2):\")\n",
    "    basis_start_time = time.time()\n",
    "    \n",
    "    for param_idx, (param_name, param_values) in enumerate(test_ranges.items()):\n",
    "        param_start_time = time.time()\n",
    "        print(f\"  [{param_idx+1}/3] Varying {param_name} ({len(param_values)} values):\", end=\" \")\n",
    "        \n",
    "        for val_idx, param_value in enumerate(param_values):\n",
    "            test_count += 1\n",
    "            print(f\"{param_value}\", end=\" \")\n",
    "            \n",
    "            # Run the test\n",
    "            test_start = time.time()\n",
    "            result = run_sensitivity_test(basis, param_name, param_value, srs_target_spec)\n",
    "            test_time = time.time() - test_start\n",
    "            result['test_id'] = test_count\n",
    "            results.append(result)\n",
    "            \n",
    "            # Progress indicators with timing\n",
    "            if val_idx == len(param_values) - 1:  # Last value for this parameter\n",
    "                param_time = time.time() - param_start_time\n",
    "                progress = (test_count / total_tests) * 100\n",
    "                print(f\"✓ ({param_time:.1f}s, {progress:.0f}% total)\")\n",
    "            elif (val_idx + 1) % 2 == 0:  # Every 2nd value\n",
    "                progress = (test_count / total_tests) * 100\n",
    "                print(f\"({progress:.0f}%)\", end=\" \")\n",
    "    \n",
    "    # Basis completion summary\n",
    "    basis_time = time.time() - basis_start_time\n",
    "    basis_tests = len([r for r in results if r['basis'] == basis])\n",
    "    success_rate = len([r for r in results if r['basis'] == basis and r['success']]) / basis_tests * 100\n",
    "    print(f\"  → {basis.title()} basis completed: {basis_tests} tests in {basis_time:.1f}s (success: {success_rate:.0f}%)\")\n",
    "\n",
    "print(f\"\\n🎉 Analysis completed! {len(results)} tests total\")\n",
    "print(f\"📊 Starting data analysis and visualization...\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df = pd.DataFrame(results)\n",
    "df_success = df[df['success'] == True].copy()  # Only successful runs\n",
    "\n",
    "print(f\"✅ Success rate: {len(df_success)}/{len(df)} = {len(df_success)/len(df)*100:.1f}%\")\n",
    "print(f\"📈 Generating visualization plots...\")\n",
    "\n",
    "# Analysis and visualization\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "\n",
    "# Color schemes\n",
    "colors = {'wavelet': 'blue', 'damped_sine': 'red'}\n",
    "markers = {'wavelet': 'o', 'damped_sine': 's'}\n",
    "\n",
    "print(\"  → Creating parameter plots:\", end=\" \")\n",
    "for i, param in enumerate(['freqs_per_octave', 'n_trials', 'inner_iters']):\n",
    "    print(f\"{param.replace('_',' ')}\", end=\" \")\n",
    "    \n",
    "    # Filter data for this parameter\n",
    "    param_data = df_success[df_success['parameter'] == param]\n",
    "    \n",
    "    # Plot 1: Runtime vs Parameter Value\n",
    "    ax = axes[i, 0]\n",
    "    for basis in ['wavelet', 'damped_sine']:\n",
    "        basis_data = param_data[param_data['basis'] == basis]\n",
    "        if len(basis_data) > 0:\n",
    "            ax.plot(basis_data['param_value'], basis_data['runtime_s'], \n",
    "                   color=colors[basis], marker=markers[basis], linewidth=2, \n",
    "                   markersize=8, label=f'{basis.title()} Basis')\n",
    "    \n",
    "    ax.set_xlabel(f'{param.replace(\"_\", \" \").title()}')\n",
    "    ax.set_ylabel('Runtime (seconds)')\n",
    "    ax.set_title(f'Runtime vs {param.replace(\"_\", \" \").title()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Fit runtime scaling (simple power law estimation)\n",
    "    for basis in ['wavelet', 'damped_sine']:\n",
    "        basis_data = param_data[param_data['basis'] == basis]\n",
    "        if len(basis_data) >= 3:  # Need at least 3 points for fitting\n",
    "            x_vals = basis_data['param_value'].values\n",
    "            y_vals = basis_data['runtime_s'].values\n",
    "            \n",
    "            # Log-log fit for power law: y = a * x^b\n",
    "            try:\n",
    "                log_x = np.log(x_vals)\n",
    "                log_y = np.log(y_vals)\n",
    "                coeffs = np.polyfit(log_x, log_y, 1)\n",
    "                scaling_exponent = coeffs[0]\n",
    "                \n",
    "                # Add scaling annotation\n",
    "                ax.text(0.05, 0.95 - (0 if basis == 'wavelet' else 0.1), \n",
    "                       f'{basis.title()}: O(N^{scaling_exponent:.2f})', \n",
    "                       transform=ax.transAxes, fontsize=9,\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor=colors[basis], alpha=0.2))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Plot 2: SRS Error vs Parameter Value\n",
    "    ax = axes[i, 1]\n",
    "    for basis in ['wavelet', 'damped_sine']:\n",
    "        basis_data = param_data[param_data['basis'] == basis]\n",
    "        if len(basis_data) > 0:\n",
    "            ax.plot(basis_data['param_value'], basis_data['srs_error_db'], \n",
    "                   color=colors[basis], marker=markers[basis], linewidth=2, \n",
    "                   markersize=8, label=f'{basis.title()} Basis')\n",
    "    \n",
    "    ax.set_xlabel(f'{param.replace(\"_\", \" \").title()}')\n",
    "    ax.set_ylabel('Max SRS Error (dB)')\n",
    "    ax.set_title(f'SRS Accuracy vs {param.replace(\"_\", \" \").title()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='1 dB Target')\n",
    "    \n",
    "    # Plot 3: Efficiency (Accuracy/Runtime) vs Parameter Value\n",
    "    ax = axes[i, 2]\n",
    "    for basis in ['wavelet', 'damped_sine']:\n",
    "        basis_data = param_data[param_data['basis'] == basis]\n",
    "        if len(basis_data) > 0:\n",
    "            # Efficiency metric: lower error and faster time is better\n",
    "            # Use 1/(error + 0.1) / runtime as efficiency (higher is better)\n",
    "            efficiency = 1.0 / (basis_data['srs_error_db'] + 0.1) / basis_data['runtime_s']\n",
    "            ax.plot(basis_data['param_value'], efficiency, \n",
    "                   color=colors[basis], marker=markers[basis], linewidth=2, \n",
    "                   markersize=8, label=f'{basis.title()} Basis')\n",
    "    \n",
    "    ax.set_xlabel(f'{param.replace(\"_\", \" \").title()}')\n",
    "    ax.set_ylabel('Efficiency (1/error/time)')\n",
    "    ax.set_title(f'Efficiency vs {param.replace(\"_\", \" \").title()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "print(\"✓\")\n",
    "print(\"🎨 Displaying plots...\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Computing summary statistics...\")\n",
    "\n",
    "# Summary statistics and recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER SENSITIVITY ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics by basis\n",
    "print(\"\\nOVERALL PERFORMANCE BY BASIS:\")\n",
    "print(f\"{'Metric':<25} {'Wavelet Mean':<15} {'Damped Sine Mean':<18} {'Winner':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "wavelet_stats = df_success[df_success['basis'] == 'wavelet']\n",
    "damped_stats = df_success[df_success['basis'] == 'damped_sine']\n",
    "\n",
    "runtime_w = wavelet_stats['runtime_s'].mean()\n",
    "runtime_d = damped_stats['runtime_s'].mean()\n",
    "error_w = wavelet_stats['srs_error_db'].mean()\n",
    "error_d = damped_stats['srs_error_db'].mean()\n",
    "peak_w = wavelet_stats['peak_accel_g'].mean()\n",
    "peak_d = damped_stats['peak_accel_g'].mean()\n",
    "\n",
    "print(f\"{'Runtime (s)':<25} {runtime_w:<15.2f} {runtime_d:<18.2f} {'Damped Sine' if runtime_d < runtime_w else 'Wavelet':<15}\")\n",
    "print(f\"{'SRS Error (dB)':<25} {error_w:<15.2f} {error_d:<18.2f} {'Wavelet' if error_w < error_d else 'Damped Sine':<15}\")\n",
    "print(f\"{'Peak Accel (g)':<25} {peak_w:<15.1f} {peak_d:<18.1f} {'Equal':<15}\")\n",
    "\n",
    "# Parameter-specific insights\n",
    "print(f\"\\nPARAMETER SCALING ANALYSIS:\")\n",
    "\n",
    "for param in ['freqs_per_octave', 'n_trials', 'inner_iters']:\n",
    "    print(f\"\\n{param.replace('_', ' ').title()}:\")\n",
    "    param_data = df_success[df_success['parameter'] == param]\n",
    "    \n",
    "    # Runtime scaling analysis\n",
    "    for basis in ['wavelet', 'damped_sine']:\n",
    "        basis_data = param_data[param_data['basis'] == basis]\n",
    "        if len(basis_data) >= 3:\n",
    "            x_vals = basis_data['param_value'].values\n",
    "            y_vals = basis_data['runtime_s'].values\n",
    "            \n",
    "            # Calculate correlation and rough scaling\n",
    "            runtime_range = y_vals.max() / y_vals.min()\n",
    "            param_range = x_vals.max() / x_vals.min()\n",
    "            \n",
    "            if runtime_range > 1.5:  # Significant runtime variation\n",
    "                try:\n",
    "                    log_x = np.log(x_vals)\n",
    "                    log_y = np.log(y_vals)\n",
    "                    scaling_exp = np.polyfit(log_x, log_y, 1)[0]\n",
    "                    print(f\"  - {basis.title()}: Runtime scales as O(N^{scaling_exp:.2f})\")\n",
    "                except:\n",
    "                    print(f\"  - {basis.title()}: Runtime scaling unclear\")\n",
    "            else:\n",
    "                print(f\"  - {basis.title()}: Runtime relatively constant\")\n",
    "    \n",
    "    # Accuracy trends\n",
    "    min_error_val = param_data.loc[param_data['srs_error_db'].idxmin(), 'param_value']\n",
    "    print(f\"  - Best accuracy at {param} = {min_error_val}\")\n",
    "\n",
    "# Optimization recommendations\n",
    "print(f\"\\n🔍 Generating optimization recommendations...\")\n",
    "print(f\"\\nFor SPEED (minimize runtime):\")\n",
    "\n",
    "speed_recommendations = {}\n",
    "for param in ['freqs_per_octave', 'n_trials', 'inner_iters']:\n",
    "    param_data = df_success[df_success['parameter'] == param]\n",
    "    fastest_setting = param_data.loc[param_data['runtime_s'].idxmin()]\n",
    "    speed_recommendations[param] = int(fastest_setting['param_value'])\n",
    "\n",
    "print(f\"  - freqs_per_octave: {speed_recommendations['freqs_per_octave']}\")\n",
    "print(f\"  - n_trials: {speed_recommendations['n_trials']}\")  \n",
    "print(f\"  - inner_iters: {speed_recommendations['inner_iters']}\")\n",
    "\n",
    "print(f\"\\nFor ACCURACY (minimize SRS error):\")\n",
    "\n",
    "accuracy_recommendations = {}\n",
    "for param in ['freqs_per_octave', 'n_trials', 'inner_iters']:\n",
    "    param_data = df_success[df_success['parameter'] == param]\n",
    "    most_accurate = param_data.loc[param_data['srs_error_db'].idxmin()]\n",
    "    accuracy_recommendations[param] = int(most_accurate['param_value'])\n",
    "\n",
    "print(f\"  - freqs_per_octave: {accuracy_recommendations['freqs_per_octave']}\")\n",
    "print(f\"  - n_trials: {accuracy_recommendations['n_trials']}\")\n",
    "print(f\"  - inner_iters: {accuracy_recommendations['inner_iters']}\")\n",
    "\n",
    "print(f\"\\nFor BALANCED performance (good accuracy in reasonable time):\")\n",
    "\n",
    "# Calculate efficiency metric for each test\n",
    "df_success['efficiency'] = 1.0 / (df_success['srs_error_db'] + 0.1) / df_success['runtime_s']\n",
    "\n",
    "balanced_recommendations = {}\n",
    "for param in ['freqs_per_octave', 'n_trials', 'inner_iters']:\n",
    "    param_data = df_success[df_success['parameter'] == param]\n",
    "    most_efficient = param_data.loc[param_data['efficiency'].idxmax()]\n",
    "    balanced_recommendations[param] = int(most_efficient['param_value'])\n",
    "\n",
    "print(f\"  - freqs_per_octave: {balanced_recommendations['freqs_per_octave']}\")\n",
    "print(f\"  - n_trials: {balanced_recommendations['n_trials']}\")\n",
    "print(f\"  - inner_iters: {balanced_recommendations['inner_iters']}\")\n",
    "\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "print(f\"• Runtime generally increases with all parameters, but at different rates\")\n",
    "print(f\"• freqs_per_octave has the strongest effect on both accuracy and runtime\")\n",
    "print(f\"• n_trials provides diminishing returns beyond ~100 trials\")\n",
    "print(f\"• inner_iters shows saturation effects - more isn't always better\")\n",
    "print(f\"• Damped sine basis typically faster, wavelet basis often more accurate\")\n",
    "print(f\"• Sweet spot for balanced performance: ~12-18 freqs/octave, ~50-100 trials, ~10-15 iterations\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP DIVE: Why Damped Sine Performs Better with Lower Parameter Values\n",
    "print(\"COUNTERINTUITIVE RESULT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Why does damped sine achieve BETTER accuracy with LOWER complexity?\")\n",
    "print()\n",
    "\n",
    "# Extract specific damped sine results for detailed analysis\n",
    "damped_results = df_success[df_success['basis'] == 'damped_sine'].copy()\n",
    "\n",
    "print(\"🔍 DETAILED DAMPED SINE RESULTS:\")\n",
    "print()\n",
    "\n",
    "# Analyze freqs_per_octave effect\n",
    "freq_results = damped_results[damped_results['parameter'] == 'freqs_per_octave'].sort_values('param_value')\n",
    "print(\"Freqs Per Octave Analysis:\")\n",
    "for _, row in freq_results.iterrows():\n",
    "    print(f\"  {row['param_value']:2d} freqs/octave → {row['srs_error_db']:.2f} dB error ({row['runtime_s']:.1f}s)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Analyze inner_iters effect  \n",
    "iter_results = damped_results[damped_results['parameter'] == 'inner_iters'].sort_values('param_value')\n",
    "print(\"Inner Iterations Analysis:\")\n",
    "for _, row in iter_results.iterrows():\n",
    "    print(f\"  {row['param_value']:2d} iterations  → {row['srs_error_db']:.2f} dB error ({row['runtime_s']:.1f}s)\")\n",
    "\n",
    "print()\n",
    "print(\"🧠 THEORETICAL EXPLANATIONS:\")\n",
    "print()\n",
    "\n",
    "print(\"1. OVERFITTING PREVENTION:\")\n",
    "print(\"   • Fewer frequency components (6/octave) → less opportunity to overfit noise\")\n",
    "print(\"   • Damped sine functions are naturally smooth and broad-band\")\n",
    "print(\"   • Too many frequencies can create competing/interfering components\")\n",
    "print(\"   • Occam's Razor: simpler models often generalize better\")\n",
    "print()\n",
    "\n",
    "print(\"2. EARLY STOPPING EFFECT:\")\n",
    "print(\"   • Fewer iterations (5) prevent over-optimization\")\n",
    "print(\"   • Damped sine basis may converge quickly due to natural spectral match\")\n",
    "print(\"   • Additional iterations may cause oscillation around optimal solution\")\n",
    "print(\"   • Prevents getting trapped in local minima\")\n",
    "print()\n",
    "\n",
    "print(\"3. BASIS FUNCTION CHARACTERISTICS:\")\n",
    "print(\"   • Damped sine: A·exp(-ζ·2πf·t)·sin(2πf·t)\")\n",
    "print(\"   • Natural bandwidth due to exponential decay (ζ parameter)\")\n",
    "print(\"   • Each component inherently covers a frequency band\")\n",
    "print(\"   • Built-in regularization through decay prevents sharp spectral features\")\n",
    "print()\n",
    "\n",
    "print(\"4. TARGET SRS CHARACTERISTICS:\")\n",
    "# Let's examine the target SRS characteristics\n",
    "print(f\"   • Target SRS range: {srs_target_spec[:,1].min():.1f} to {srs_target_spec[:,1].max():.1f} g\")\n",
    "print(f\"   • Frequency range: {srs_target_spec[0,0]:.0f} to {srs_target_spec[-1,0]:.0f} Hz\")\n",
    "srs_smoothness = np.std(np.diff(np.log10(srs_target_spec[:,1])))\n",
    "print(f\"   • SRS smoothness metric: {srs_smoothness:.3f} (lower = smoother)\")\n",
    "print(\"   • Half-sine pulse produces relatively smooth, broad-band SRS\")\n",
    "print(\"   • Coarse sampling may be sufficient for smooth targets\")\n",
    "print()\n",
    "\n",
    "print(\"5. COMPARISON WITH WAVELET BASIS:\")\n",
    "wavelet_freq_results = df_success[(df_success['basis'] == 'wavelet') & \n",
    "                                 (df_success['parameter'] == 'freqs_per_octave')].sort_values('param_value')\n",
    "wavelet_iter_results = df_success[(df_success['basis'] == 'wavelet') & \n",
    "                                 (df_success['parameter'] == 'inner_iters')].sort_values('param_value')\n",
    "\n",
    "print(\"   Wavelet vs Damped Sine - Freqs Per Octave:\")\n",
    "for (_, w_row), (_, d_row) in zip(wavelet_freq_results.iterrows(), freq_results.iterrows()):\n",
    "    improvement = w_row['srs_error_db'] - d_row['srs_error_db']\n",
    "    print(f\"   {w_row['param_value']:2d} freqs: Wavelet {w_row['srs_error_db']:.2f}dB vs Damped {d_row['srs_error_db']:.2f}dB → {improvement:+.2f}dB advantage\")\n",
    "\n",
    "print()\n",
    "print(\"   Wavelet vs Damped Sine - Inner Iterations:\")\n",
    "for (_, w_row), (_, d_row) in zip(wavelet_iter_results.iterrows(), iter_results.iterrows()):\n",
    "    improvement = w_row['srs_error_db'] - d_row['srs_error_db']\n",
    "    print(f\"   {w_row['param_value']:2d} iters: Wavelet {w_row['srs_error_db']:.2f}dB vs Damped {d_row['srs_error_db']:.2f}dB → {improvement:+.2f}dB advantage\")\n",
    "\n",
    "print()\n",
    "print(\"💡 KEY INSIGHTS:\")\n",
    "print(\"   • Damped sine basis is inherently well-suited for shock-like signals\")\n",
    "print(\"   • Natural exponential decay matches physical shock dissipation\")\n",
    "print(\"   • Lower complexity settings prevent overfitting to numerical artifacts\")\n",
    "print(\"   • Demonstrates importance of matching basis functions to signal physics\")\n",
    "print(\"   • Sometimes 'less is more' in optimization - avoid over-parameterization\")\n",
    "\n",
    "print()\n",
    "print(\"🎯 PRACTICAL RECOMMENDATIONS:\")\n",
    "print(\"   • For damped sine basis: Use 6-12 freqs/octave, 5-10 inner iterations\")\n",
    "print(\"   • For wavelet basis: Can handle higher complexity (more robust to overfitting)\")\n",
    "print(\"   • Consider target signal characteristics when choosing parameters\")\n",
    "print(\"   • Monitor for overfitting when increasing parameter complexity\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
